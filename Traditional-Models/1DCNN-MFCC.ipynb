{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea41107-741d-4c1c-afee-b56d2b3e9aa9",
   "metadata": {},
   "source": [
    "## Malayalam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2db05a-b4c5-48c3-80db-739d1bc0768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:10:05.005417: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-29 18:10:05.017116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-29 18:10:05.029778: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-29 18:10:05.033570: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-29 18:10:05.044464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-29 18:10:08.791568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "6455 train sequences\n",
      "1614 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dist_home/common-apps/conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-29 18:10:53.214427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79078 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:41:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1520</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1520</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,084</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m31,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1520\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1520\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m6,084\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,324</span> (196.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,324\u001b[0m (196.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,228</span> (196.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,228\u001b[0m (196.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743252057.168880 1318606 service.cc:146] XLA service 0x778bc40055e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743252057.168920 1318606 service.cc:154]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2025-03-29 18:10:57.235483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-03-29 18:10:57.424650: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 63/269\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3430 - loss: 4.4072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743252060.503959 1318606 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.4194 - loss: 3.6060 - val_accuracy: 0.5496 - val_loss: 1.6871\n",
      "Epoch 2/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5185 - loss: 2.2102 - val_accuracy: 0.5700 - val_loss: 1.6998\n",
      "Epoch 3/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5525 - loss: 1.6399 - val_accuracy: 0.5081 - val_loss: 1.7818\n",
      "Epoch 4/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6343 - loss: 1.3202 - val_accuracy: 0.7107 - val_loss: 1.1094\n",
      "Epoch 5/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6900 - loss: 1.1585 - val_accuracy: 0.6939 - val_loss: 1.1787\n",
      "Epoch 6/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7151 - loss: 1.0579 - val_accuracy: 0.6388 - val_loss: 1.0931\n",
      "Epoch 7/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.9713 - val_accuracy: 0.7615 - val_loss: 0.9159\n",
      "Epoch 8/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7548 - loss: 0.8950 - val_accuracy: 0.5285 - val_loss: 1.3238\n",
      "Epoch 9/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.8353 - val_accuracy: 0.5632 - val_loss: 1.4012\n",
      "Epoch 10/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7590 - loss: 0.8162 - val_accuracy: 0.6989 - val_loss: 0.8909\n",
      "Epoch 11/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.7517 - val_accuracy: 0.6629 - val_loss: 0.9556\n",
      "Epoch 12/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7927 - loss: 0.6976 - val_accuracy: 0.7565 - val_loss: 0.7210\n",
      "Epoch 13/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.6934 - val_accuracy: 0.7565 - val_loss: 0.7351\n",
      "Epoch 14/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.6579 - val_accuracy: 0.7515 - val_loss: 0.7191\n",
      "Epoch 15/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.6385 - val_accuracy: 0.6952 - val_loss: 0.7858\n",
      "Epoch 16/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.6077 - val_accuracy: 0.6995 - val_loss: 0.8807\n",
      "Epoch 17/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.6173 - val_accuracy: 0.7410 - val_loss: 0.7609\n",
      "Epoch 18/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5994 - val_accuracy: 0.6276 - val_loss: 0.9859\n",
      "Epoch 19/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.5852 - val_accuracy: 0.6704 - val_loss: 0.8055\n",
      "Epoch 20/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.5528 - val_accuracy: 0.7850 - val_loss: 0.5992\n",
      "Epoch 21/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.5593 - val_accuracy: 0.7323 - val_loss: 0.9455\n",
      "Epoch 22/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7988 - loss: 0.5727 - val_accuracy: 0.7274 - val_loss: 0.7998\n",
      "Epoch 23/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5646 - val_accuracy: 0.6425 - val_loss: 1.0481\n",
      "Epoch 24/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8032 - loss: 0.5711 - val_accuracy: 0.6983 - val_loss: 0.7844\n",
      "Epoch 25/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.5453 - val_accuracy: 0.5830 - val_loss: 1.3363\n",
      "Epoch 26/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.5370 - val_accuracy: 0.5502 - val_loss: 1.5989\n",
      "Epoch 27/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.5410 - val_accuracy: 0.6072 - val_loss: 1.6056\n",
      "Epoch 28/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.5268 - val_accuracy: 0.5954 - val_loss: 0.9777\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7657 - loss: 0.6185\n",
      "Test loss: 0.5992317199707031\n",
      "Test accuracy: 0.7850062251091003\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Kozhikode       0.85      0.96      0.90       484\n",
      "    Kottayam       0.64      0.84      0.73       335\n",
      "  Trivandrum       0.84      0.65      0.73       360\n",
      "    Thrissur       0.83      0.66      0.73       435\n",
      "\n",
      "    accuracy                           0.79      1614\n",
      "   macro avg       0.79      0.78      0.77      1614\n",
      "weighted avg       0.80      0.79      0.78      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Setting parameters\n",
    "test_dim = 431  # Dimension to pad/truncate MFCC features\n",
    "batch_size = 24  # Batch size for training\n",
    "nb_filter = 16  # Number of filters in Conv1D layers\n",
    "filter_length_1 = 50  # Length of the first filter\n",
    "filter_length_2 = 25  # Length of the second filter\n",
    "nb_epoch = 50  # Number of epochs for training\n",
    "hidden_dims = 64  # Number of hidden units in Dense layer\n",
    "n_mfcc = 39  # Number of MFCC coefficients\n",
    "hop_length = 512  # Hop length for MFCC extraction\n",
    "n_fft = 480  # FFT window size\n",
    "\n",
    "# Function to load audio files and extract MFCC features\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_labels = {}\n",
    "    class_index = 0\n",
    "\n",
    "    for subdir, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                label = os.path.basename(subdir)\n",
    "                if label not in class_labels:\n",
    "                    class_labels[label] = class_index\n",
    "                    class_index += 1\n",
    "                \n",
    "                # Load audio file and extract MFCC features\n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "                mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)  # Normalize MFCC features\n",
    "                if mfcc.shape[1] < test_dim:\n",
    "                    mfcc = np.pad(mfcc, ((0, 0), (0, test_dim - mfcc.shape[1])), mode='constant')\n",
    "                else:\n",
    "                    mfcc = mfcc[:, :test_dim]\n",
    "                X.append(mfcc.T)\n",
    "                y.append(class_labels[label])\n",
    "    \n",
    "    return np.array(X), np.array(y), class_labels\n",
    "\n",
    "# Load data\n",
    "data_dir = '/dist_home/jairam/Malayalam/'\n",
    "print('Loading data...')\n",
    "X, y, class_labels = load_data(data_dir)\n",
    "\n",
    "# Ensure X has the correct shape for Conv1D input (batch_size, steps, input_dim)\n",
    "X = np.expand_dims(X, -1)  # Add a new axis to match (batch_size, steps, input_dim, 1)\n",
    "\n",
    "# Shuffle the data before splitting\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "nb_classes = len(class_labels)  # Update number of classes based on data\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Define the model with additional regularization and learning rate scheduling\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with BatchNormalization and Dropout\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_1,\n",
    "                 input_shape=(test_dim, n_mfcc),  # Adjusted input shape for Conv1D\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Flatten the output of the conv layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dropout for regularization\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Add output layer with softmax activation for multiclass classification\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model with a learning rate schedule\n",
    "initial_learning_rate = 0.0005\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=batch_size, validation_data=(X_test, Y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Generate classification report\n",
    "y_preds = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_preds, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=list(class_labels.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc60f7-6749-4663-b5e3-76a95721555c",
   "metadata": {},
   "source": [
    "## 1D-CNN for Tamil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4fe6a8-5e81-42b1-9fe0-b8f8de8b308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "5948 train sequences\n",
      "1487 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dist_home/common-apps/conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1520</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1520</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,084</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m31,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1520\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1520\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m6,084\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,324</span> (196.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,324\u001b[0m (196.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,228</span> (196.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,228\u001b[0m (196.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.4515 - loss: 3.1356 - val_accuracy: 0.7337 - val_loss: 1.0693\n",
      "Epoch 2/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 1.6622 - val_accuracy: 0.5931 - val_loss: 1.6879\n",
      "Epoch 3/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 1.2636 - val_accuracy: 0.6785 - val_loss: 1.1636\n",
      "Epoch 4/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 1.0732 - val_accuracy: 0.7068 - val_loss: 1.3377\n",
      "Epoch 5/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.9431 - val_accuracy: 0.6295 - val_loss: 1.3549\n",
      "Epoch 6/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.8511 - val_accuracy: 0.7754 - val_loss: 0.7857\n",
      "Epoch 7/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.7642 - val_accuracy: 0.6752 - val_loss: 1.2810\n",
      "Epoch 8/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.7106 - val_accuracy: 0.8406 - val_loss: 0.6429\n",
      "Epoch 9/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.6538 - val_accuracy: 0.8366 - val_loss: 0.6181\n",
      "Epoch 10/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.6621 - val_accuracy: 0.7297 - val_loss: 0.7607\n",
      "Epoch 11/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.6430 - val_accuracy: 0.7599 - val_loss: 0.7800\n",
      "Epoch 12/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.5968 - val_accuracy: 0.7599 - val_loss: 0.6868\n",
      "Epoch 13/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.5751 - val_accuracy: 0.8056 - val_loss: 0.6179\n",
      "Epoch 14/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.5419 - val_accuracy: 0.7149 - val_loss: 1.0482\n",
      "Epoch 15/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.5113 - val_accuracy: 0.7041 - val_loss: 0.8566\n",
      "Epoch 16/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.5099 - val_accuracy: 0.7868 - val_loss: 0.5668\n",
      "Epoch 17/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.5023 - val_accuracy: 0.7579 - val_loss: 0.6425\n",
      "Epoch 18/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8369 - loss: 0.4744 - val_accuracy: 0.7814 - val_loss: 0.5700\n",
      "Epoch 19/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.4567 - val_accuracy: 0.7586 - val_loss: 0.6268\n",
      "Epoch 20/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.4459 - val_accuracy: 0.6194 - val_loss: 0.9958\n",
      "Epoch 21/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.4396 - val_accuracy: 0.7761 - val_loss: 0.5412\n",
      "Epoch 22/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.4136 - val_accuracy: 0.8009 - val_loss: 0.5159\n",
      "Epoch 23/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.4380 - val_accuracy: 0.7142 - val_loss: 1.4104\n",
      "Epoch 24/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.4077 - val_accuracy: 0.6812 - val_loss: 0.9199\n",
      "Epoch 25/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.4128 - val_accuracy: 0.8574 - val_loss: 0.3839\n",
      "Epoch 26/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.4238 - val_accuracy: 0.8117 - val_loss: 0.5290\n",
      "Epoch 27/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.4032 - val_accuracy: 0.6436 - val_loss: 1.1114\n",
      "Epoch 28/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8262 - loss: 0.4458 - val_accuracy: 0.8030 - val_loss: 0.4977\n",
      "Epoch 29/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.4073 - val_accuracy: 0.8009 - val_loss: 0.4570\n",
      "Epoch 30/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.3920 - val_accuracy: 0.7848 - val_loss: 0.5956\n",
      "Epoch 31/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.4023 - val_accuracy: 0.7256 - val_loss: 0.8003\n",
      "Epoch 32/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8561 - loss: 0.3885 - val_accuracy: 0.7606 - val_loss: 0.6159\n",
      "Epoch 33/50\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.4233 - val_accuracy: 0.5918 - val_loss: 1.2429\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8678 - loss: 0.3648\n",
      "Test loss: 0.3838871121406555\n",
      "Test accuracy: 0.8574310541152954\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Coimbatore       0.99      0.90      0.94       385\n",
      "     Madurai       0.91      0.99      0.94       388\n",
      " Thoothukudi       0.75      0.81      0.78       369\n",
      "     Chennai       0.78      0.72      0.75       345\n",
      "\n",
      "    accuracy                           0.86      1487\n",
      "   macro avg       0.86      0.85      0.85      1487\n",
      "weighted avg       0.86      0.86      0.86      1487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Setting parameters\n",
    "test_dim = 431  # Dimension to pad/truncate MFCC features\n",
    "batch_size = 24  # Batch size for training\n",
    "nb_filter = 16  # Number of filters in Conv1D layers\n",
    "filter_length_1 = 50  # Length of the first filter\n",
    "filter_length_2 = 25  # Length of the second filter\n",
    "nb_epoch = 50  # Number of epochs for training\n",
    "hidden_dims = 64  # Number of hidden units in Dense layer\n",
    "n_mfcc = 39  # Number of MFCC coefficients\n",
    "hop_length = 512  # Hop length for MFCC extraction\n",
    "n_fft = 480  # FFT window size\n",
    "\n",
    "# Function to load audio files and extract MFCC features\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_labels = {}\n",
    "    class_index = 0\n",
    "\n",
    "    for subdir, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                label = os.path.basename(subdir)\n",
    "                if label not in class_labels:\n",
    "                    class_labels[label] = class_index\n",
    "                    class_index += 1\n",
    "                \n",
    "                # Load audio file and extract MFCC features\n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "                mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)  # Normalize MFCC features\n",
    "                if mfcc.shape[1] < test_dim:\n",
    "                    mfcc = np.pad(mfcc, ((0, 0), (0, test_dim - mfcc.shape[1])), mode='constant')\n",
    "                else:\n",
    "                    mfcc = mfcc[:, :test_dim]\n",
    "                X.append(mfcc.T)\n",
    "                y.append(class_labels[label])\n",
    "    \n",
    "    return np.array(X), np.array(y), class_labels\n",
    "\n",
    "# Load data\n",
    "data_dir = '/dist_home/jairam/Tamil/'\n",
    "print('Loading data...')\n",
    "X, y, class_labels = load_data(data_dir)\n",
    "\n",
    "# Ensure X has the correct shape for Conv1D input (batch_size, steps, input_dim)\n",
    "X = np.expand_dims(X, -1)  # Add a new axis to match (batch_size, steps, input_dim, 1)\n",
    "\n",
    "# Shuffle the data before splitting\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "nb_classes = len(class_labels)  # Update number of classes based on data\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Define the model with additional regularization and learning rate scheduling\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with BatchNormalization and Dropout\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_1,\n",
    "                 input_shape=(test_dim, n_mfcc),  # Adjusted input shape for Conv1D\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Flatten the output of the conv layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dropout for regularization\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Add output layer with softmax activation for multiclass classification\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model with a learning rate schedule\n",
    "initial_learning_rate = 0.0005\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=batch_size, validation_data=(X_test, Y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Generate classification report\n",
    "y_preds = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_preds, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=list(class_labels.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc113f-ce16-4843-877b-b243e633798f",
   "metadata": {},
   "source": [
    "## Kannada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44f6d8a-caf2-43a0-8d47-0263d26de796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "6456 train sequences\n",
      "1615 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dist_home/common-apps/conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">382</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1520</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1520</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,084</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m31,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m382\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1520\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1520\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m6,084\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,324</span> (196.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,324\u001b[0m (196.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,228</span> (196.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,228\u001b[0m (196.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2466 - loss: 4.5016 - val_accuracy: 0.3152 - val_loss: 2.0169\n",
      "Epoch 2/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3924 - loss: 2.3598 - val_accuracy: 0.5858 - val_loss: 1.4249\n",
      "Epoch 3/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4961 - loss: 1.6922 - val_accuracy: 0.5975 - val_loss: 1.3461\n",
      "Epoch 4/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5628 - loss: 1.4869 - val_accuracy: 0.5895 - val_loss: 1.3440\n",
      "Epoch 5/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 1.2932 - val_accuracy: 0.6105 - val_loss: 1.3416\n",
      "Epoch 6/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 1.2237 - val_accuracy: 0.5492 - val_loss: 1.6433\n",
      "Epoch 7/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7033 - loss: 1.1095 - val_accuracy: 0.7356 - val_loss: 0.9797\n",
      "Epoch 8/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 1.0804 - val_accuracy: 0.5901 - val_loss: 1.4183\n",
      "Epoch 9/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7324 - loss: 0.9822 - val_accuracy: 0.6817 - val_loss: 1.0368\n",
      "Epoch 10/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.9913 - val_accuracy: 0.7585 - val_loss: 0.8782\n",
      "Epoch 11/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.9465 - val_accuracy: 0.3777 - val_loss: 2.9657\n",
      "Epoch 12/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7517 - loss: 0.8913 - val_accuracy: 0.5647 - val_loss: 1.2839\n",
      "Epoch 13/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7486 - loss: 0.8581 - val_accuracy: 0.5424 - val_loss: 1.6371\n",
      "Epoch 14/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.8229 - val_accuracy: 0.6167 - val_loss: 1.2149\n",
      "Epoch 15/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.8147 - val_accuracy: 0.6638 - val_loss: 1.1075\n",
      "Epoch 16/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.7902 - val_accuracy: 0.5529 - val_loss: 1.4935\n",
      "Epoch 17/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.7780 - val_accuracy: 0.6322 - val_loss: 1.1922\n",
      "Epoch 18/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.7338 - val_accuracy: 0.7164 - val_loss: 0.8735\n",
      "Epoch 19/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.7414 - val_accuracy: 0.6130 - val_loss: 1.5014\n",
      "Epoch 20/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7872 - loss: 0.7147 - val_accuracy: 0.5517 - val_loss: 1.8280\n",
      "Epoch 21/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.7333 - val_accuracy: 0.5059 - val_loss: 1.4913\n",
      "Epoch 22/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.7181 - val_accuracy: 0.7486 - val_loss: 0.8818\n",
      "Epoch 23/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.7074 - val_accuracy: 0.4198 - val_loss: 1.7470\n",
      "Epoch 24/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.6971 - val_accuracy: 0.5721 - val_loss: 1.3369\n",
      "Epoch 25/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.6960 - val_accuracy: 0.6997 - val_loss: 1.0879\n",
      "Epoch 26/50\n",
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.6484 - val_accuracy: 0.6118 - val_loss: 1.1339\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7244 - loss: 0.8362\n",
      "Test loss: 0.8735450506210327\n",
      "Test accuracy: 0.7164086699485779\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Kundapura       0.89      0.77      0.82       410\n",
      "     Coastal       0.93      0.63      0.75       418\n",
      "       North       0.93      0.53      0.68       390\n",
      "     Mandhya       0.49      0.93      0.65       397\n",
      "\n",
      "    accuracy                           0.72      1615\n",
      "   macro avg       0.81      0.72      0.72      1615\n",
      "weighted avg       0.81      0.72      0.73      1615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Setting parameters\n",
    "test_dim = 431  # Dimension to pad/truncate MFCC features\n",
    "batch_size = 24  # Batch size for training\n",
    "nb_filter = 16  # Number of filters in Conv1D layers\n",
    "filter_length_1 = 50  # Length of the first filter\n",
    "filter_length_2 = 25  # Length of the second filter\n",
    "nb_epoch = 50  # Number of epochs for training\n",
    "hidden_dims = 64  # Number of hidden units in Dense layer\n",
    "n_mfcc = 39  # Number of MFCC coefficients\n",
    "hop_length = 512  # Hop length for MFCC extraction\n",
    "n_fft = 480  # FFT window size\n",
    "\n",
    "# Function to load audio files and extract MFCC features\n",
    "def load_data(data_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_labels = {}\n",
    "    class_index = 0\n",
    "\n",
    "    for subdir, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                label = os.path.basename(subdir)\n",
    "                if label not in class_labels:\n",
    "                    class_labels[label] = class_index\n",
    "                    class_index += 1\n",
    "                \n",
    "                # Load audio file and extract MFCC features\n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "                mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)  # Normalize MFCC features\n",
    "                if mfcc.shape[1] < test_dim:\n",
    "                    mfcc = np.pad(mfcc, ((0, 0), (0, test_dim - mfcc.shape[1])), mode='constant')\n",
    "                else:\n",
    "                    mfcc = mfcc[:, :test_dim]\n",
    "                X.append(mfcc.T)\n",
    "                y.append(class_labels[label])\n",
    "    \n",
    "    return np.array(X), np.array(y), class_labels\n",
    "\n",
    "# Load data\n",
    "data_dir = '/dist_home/jairam/Kannada/'\n",
    "print('Loading data...')\n",
    "X, y, class_labels = load_data(data_dir)\n",
    "\n",
    "# Ensure X has the correct shape for Conv1D input (batch_size, steps, input_dim)\n",
    "X = np.expand_dims(X, -1)  # Add a new axis to match (batch_size, steps, input_dim, 1)\n",
    "\n",
    "# Shuffle the data before splitting\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "nb_classes = len(class_labels)  # Update number of classes based on data\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Define the model with additional regularization and learning rate scheduling\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with BatchNormalization and Dropout\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_1,\n",
    "                 input_shape=(test_dim, n_mfcc),  # Adjusted input shape for Conv1D\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Conv1D(filters=nb_filter,\n",
    "                 kernel_size=filter_length_2,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Flatten the output of the conv layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dropout for regularization\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Add output layer with softmax activation for multiclass classification\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model with a learning rate schedule\n",
    "initial_learning_rate = 0.0005\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=batch_size, validation_data=(X_test, Y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Generate classification report\n",
    "y_preds = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_preds, axis=1)\n",
    "y_true_classes = np.argmax(Y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=list(class_labels.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b656e73-0f9b-4e7f-a817-9426234a7940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
